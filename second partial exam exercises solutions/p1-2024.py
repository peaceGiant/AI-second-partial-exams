from sklearn.preprocessing import MinMaxScaler
from sklearn.naive_bayes import GaussianNB

dataset = [[7.4, 0.7, 0, 1.9, 0.076, 11, 34, 0.9978, 3.51, 0.56, 9.4, 'bad'], [7.8, 0.88, 0, 2.6, 0.098, 25, 67, 0.9968, 3.2, 0.68, 9.8, 'bad'], [7.8, 0.76, 0.04, 2.3, 0.092, 15, 54, 0.997, 3.26, 0.65, 9.8, 'bad'], [11.2, 0.28, 0.56, 1.9, 0.075, 17, 60, 0.998, 3.16, 0.58, 9.8, 'good'], [7.4, 0.7, 0, 1.9, 0.076, 11, 34, 0.9978, 3.51, 0.56, 9.4, 'bad'], [7.4, 0.66, 0, 1.8, 0.075, 13, 40, 0.9978, 3.51, 0.56, 9.4, 'bad'], [7.9, 0.6, 0.06, 1.6, 0.069, 15, 59, 0.9964, 3.3, 0.46, 9.4, 'bad'], [7.3, 0.65, 0, 1.2, 0.065, 15, 21, 0.9946, 3.39, 0.47, 10, 'good'], [7.8, 0.58, 0.02, 2, 0.073, 9, 18, 0.9968, 3.36, 0.57, 9.5, 'good'], [7.5, 0.5, 0.36, 6.1, 0.071, 17, 102, 0.9978, 3.35, 0.8, 10.5, 'bad'], [6.7, 0.58, 0.08, 1.8, 0.097, 15, 65, 0.9959, 3.28, 0.54, 9.2, 'bad'], [7.5, 0.5, 0.36, 6.1, 0.071, 17, 102, 0.9978, 3.35, 0.8, 10.5, 'bad'], [5.6, 0.615, 0, 1.6, 0.089, 16, 59, 0.9943, 3.58, 0.52, 9.9, 'bad'], [7.8, 0.61, 0.29, 1.6, 0.114, 9, 29, 0.9974, 3.26, 1.56, 9.1, 'bad'], [8.9, 0.62, 0.18, 3.8, 0.176, 52, 145, 0.9986, 3.16, 0.88, 9.2, 'bad'], [8.9, 0.62, 0.19, 3.9, 0.17, 51, 148, 0.9986, 3.17, 0.93, 9.2, 'bad'], [8.5, 0.28, 0.56, 1.8, 0.092, 35, 103, 0.9969, 3.3, 0.75, 10.5, 'good'], [8.1, 0.56, 0.28, 1.7, 0.368, 16, 56, 0.9968, 3.11, 1.28, 9.3, 'bad'], [7.4, 0.59, 0.08, 4.4, 0.086, 6, 29, 0.9974, 3.38, 0.5, 9, 'bad'], [7.9, 0.32, 0.51, 1.8, 0.341, 17, 56, 0.9969, 3.04, 1.08, 9.2, 'good'], [8.9, 0.22, 0.48, 1.8, 0.077, 29, 60, 0.9968, 3.39, 0.53, 9.4, 'good'], [7.6, 0.39, 0.31, 2.3, 0.082, 23, 71, 0.9982, 3.52, 0.65, 9.7, 'bad'], [7.9, 0.43, 0.21, 1.6, 0.106, 10, 37, 0.9966, 3.17, 0.91, 9.5, 'bad'], [8.5, 0.49, 0.11, 2.3, 0.084, 9, 67, 0.9968, 3.17, 0.53, 9.4, 'bad'], [6.9, 0.4, 0.14, 2.4, 0.085, 21, 40, 0.9968, 3.43, 0.63, 9.7, 'good'], [6.3, 0.39, 0.16, 1.4, 0.08, 11, 23, 0.9955, 3.34, 0.56, 9.3, 'bad'], [7.6, 0.41, 0.24, 1.8, 0.08, 4, 11, 0.9962, 3.28, 0.59, 9.5, 'bad'], [7.9, 0.43, 0.21, 1.6, 0.106, 10, 37, 0.9966, 3.17, 0.91, 9.5, 'bad'], [7.1, 0.71, 0, 1.9, 0.08, 14, 35, 0.9972, 3.47, 0.55, 9.4, 'bad'], [7.8, 0.645, 0, 2, 0.082, 8, 16, 0.9964, 3.38, 0.59, 9.8, 'good'], [6.7, 0.675, 0.07, 2.4, 0.089, 17, 82, 0.9958, 3.35, 0.54, 10.1, 'bad'], [6.9, 0.685, 0, 2.5, 0.105, 22, 37, 0.9966, 3.46, 0.57, 10.6, 'good'], [8.3, 0.655, 0.12, 2.3, 0.083, 15, 113, 0.9966, 3.17, 0.66, 9.8, 'bad'], [6.9, 0.605, 0.12, 10.7, 0.073, 40, 83, 0.9993, 3.45, 0.52, 9.4, 'good'], [5.2, 0.32, 0.25, 1.8, 0.103, 13, 50, 0.9957, 3.38, 0.55, 9.2, 'bad'], [7.8, 0.645, 0, 5.5, 0.086, 5, 18, 0.9986, 3.4, 0.55, 9.6, 'good'], [7.8, 0.6, 0.14, 2.4, 0.086, 3, 15, 0.9975, 3.42, 0.6, 10.8, 'good'], [8.1, 0.38, 0.28, 2.1, 0.066, 13, 30, 0.9968, 3.23, 0.73, 9.7, 'good'], [5.7, 1.13, 0.09, 1.5, 0.172, 7, 19, 0.994, 3.5, 0.48, 9.8, 'bad'], [7.3, 0.45, 0.36, 5.9, 0.074, 12, 87, 0.9978, 3.33, 0.83, 10.5, 'bad'], [7.3, 0.45, 0.36, 5.9, 0.074, 12, 87, 0.9978, 3.33, 0.83, 10.5, 'bad'], [8.8, 0.61, 0.3, 2.8, 0.088, 17, 46, 0.9976, 3.26, 0.51, 9.3, 'bad'], [7.5, 0.49, 0.2, 2.6, 0.332, 8, 14, 0.9968, 3.21, 0.9, 10.5, 'good'], [8.1, 0.66, 0.22, 2.2, 0.069, 9, 23, 0.9968, 3.3, 1.2, 10.3, 'bad'], [6.8, 0.67, 0.02, 1.8, 0.05, 5, 11, 0.9962, 3.48, 0.52, 9.5, 'bad'], [4.6, 0.52, 0.15, 2.1, 0.054, 8, 65, 0.9934, 3.9, 0.56, 13.1, 'bad'], [7.7, 0.935, 0.43, 2.2, 0.114, 22, 114, 0.997, 3.25, 0.73, 9.2, 'bad'], [8.7, 0.29, 0.52, 1.6, 0.113, 12, 37, 0.9969, 3.25, 0.58, 9.5, 'bad'], [6.4, 0.4, 0.23, 1.6, 0.066, 5, 12, 0.9958, 3.34, 0.56, 9.2, 'bad'], [5.6, 0.31, 0.37, 1.4, 0.074, 12, 96, 0.9954, 3.32, 0.58, 9.2, 'bad'], [8.8, 0.66, 0.26, 1.7, 0.074, 4, 23, 0.9971, 3.15, 0.74, 9.2, 'bad'], [6.6, 0.52, 0.04, 2.2, 0.069, 8, 15, 0.9956, 3.4, 0.63, 9.4, 'good'], [6.6, 0.5, 0.04, 2.1, 0.068, 6, 14, 0.9955, 3.39, 0.64, 9.4, 'good'], [8.6, 0.38, 0.36, 3, 0.081, 30, 119, 0.997, 3.2, 0.56, 9.4, 'bad'], [7.6, 0.51, 0.15, 2.8, 0.11, 33, 73, 0.9955, 3.17, 0.63, 10.2, 'good'], [7.7, 0.62, 0.04, 3.8, 0.084, 25, 45, 0.9978, 3.34, 0.53, 9.5, 'bad'], [8.4, 0.37, 0.43, 2.3, 0.063, 12, 19, 0.9955, 3.17, 0.81, 11.2, 'good'], [6.5, 0.63, 0.33, 1.8, 0.059, 16, 28, 0.99531, 3.36, 0.64, 10.1, 'good'], [7, 0.57, 0.02, 2, 0.072, 17, 26, 0.99575, 3.36, 0.61, 10.2, 'bad'], [6.3, 0.6, 0.1, 1.6, 0.048, 12, 26, 0.99306, 3.55, 0.51, 12.1, 'bad'], [11.2, 0.4, 0.5, 2, 0.099, 19, 50, 0.99783, 3.1, 0.58, 10.4, 'bad'], [7.4, 0.36, 0.3, 1.8, 0.074, 17, 24, 0.99419, 3.24, 0.7, 11.4, 'good'], [7.1, 0.68, 0, 2.3, 0.087, 17, 26, 0.99783, 3.45, 0.53, 9.5, 'bad'], [7.1, 0.67, 0, 2.3, 0.083, 18, 27, 0.99768, 3.44, 0.54, 9.4, 'bad'], [6.3, 0.68, 0.01, 3.7, 0.103, 32, 54, 0.99586, 3.51, 0.66, 11.3, 'good'], [7.3, 0.735, 0, 2.2, 0.08, 18, 28, 0.99765, 3.41, 0.6, 9.4, 'bad'], [6.6, 0.855, 0.02, 2.4, 0.062, 15, 23, 0.99627, 3.54, 0.6, 11, 'good'], [7, 0.56, 0.17, 1.7, 0.065, 15, 24, 0.99514, 3.44, 0.68, 10.55, 'good'], [6.6, 0.88, 0.04, 2.2, 0.066, 12, 20, 0.99636, 3.53, 0.56, 9.9, 'bad'], [6.6, 0.855, 0.02, 2.4, 0.062, 15, 23, 0.99627, 3.54, 0.6, 11, 'good'], [6.9, 0.63, 0.33, 6.7, 0.235, 66, 115, 0.99787, 3.22, 0.56, 9.5, 'bad'], [7.8, 0.6, 0.26, 2, 0.08, 31, 131, 0.99622, 3.21, 0.52, 9.9, 'bad'], [7.8, 0.6, 0.26, 2, 0.08, 31, 131, 0.99622, 3.21, 0.52, 9.9, 'bad'], [7.8, 0.6, 0.26, 2, 0.08, 31, 131, 0.99622, 3.21, 0.52, 9.9, 'bad'], [7.2, 0.695, 0.13, 2, 0.076, 12, 20, 0.99546, 3.29, 0.54, 10.1, 'bad'], [7.2, 0.695, 0.13, 2, 0.076, 12, 20, 0.99546, 3.29, 0.54, 10.1, 'bad'], [7.2, 0.695, 0.13, 2, 0.076, 12, 20, 0.99546, 3.29, 0.54, 10.1, 'bad'], [6.7, 0.67, 0.02, 1.9, 0.061, 26, 42, 0.99489, 3.39, 0.82, 10.9, 'good'], [6.7, 0.16, 0.64, 2.1, 0.059, 24, 52, 0.99494, 3.34, 0.71, 11.2, 'good'], [7.2, 0.695, 0.13, 2, 0.076, 12, 20, 0.99546, 3.29, 0.54, 10.1, 'bad'], [7, 0.56, 0.13, 1.6, 0.077, 25, 42, 0.99629, 3.34, 0.59, 9.2, 'bad'], [6.2, 0.51, 0.14, 1.9, 0.056, 15, 34, 0.99396, 3.48, 0.57, 11.5, 'good'], [6.4, 0.36, 0.53, 2.2, 0.23, 19, 35, 0.9934, 3.37, 0.93, 12.4, 'good'], [6.4, 0.38, 0.14, 2.2, 0.038, 15, 25, 0.99514, 3.44, 0.65, 11.1, 'good'], [7.3, 0.69, 0.32, 2.2, 0.069, 35, 104, 0.99632, 3.33, 0.51, 9.5, 'bad'], [6, 0.58, 0.2, 2.4, 0.075, 15, 50, 0.99467, 3.58, 0.67, 12.5, 'good'], [5.6, 0.31, 0.78, 13.9, 0.074, 23, 92, 0.99677, 3.39, 0.48, 10.5, 'good'], [7.5, 0.52, 0.4, 2.2, 0.06, 12, 20, 0.99474, 3.26, 0.64, 11.8, 'good'], [8, 0.3, 0.63, 1.6, 0.081, 16, 29, 0.99588, 3.3, 0.78, 10.8, 'good'], [6.2, 0.7, 0.15, 5.1, 0.076, 13, 27, 0.99622, 3.54, 0.6, 11.9, 'good'], [6.8, 0.67, 0.15, 1.8, 0.118, 13, 20, 0.9954, 3.42, 0.67, 11.3, 'good'], [6.2, 0.56, 0.09, 1.7, 0.053, 24, 32, 0.99402, 3.54, 0.6, 11.3, 'bad'], [7.4, 0.35, 0.33, 2.4, 0.068, 9, 26, 0.9947, 3.36, 0.6, 11.9, 'good'], [6.2, 0.56, 0.09, 1.7, 0.053, 24, 32, 0.99402, 3.54, 0.6, 11.3, 'bad'], [6.1, 0.715, 0.1, 2.6, 0.053, 13, 27, 0.99362, 3.57, 0.5, 11.9, 'bad'], [6.2, 0.46, 0.29, 2.1, 0.074, 32, 98, 0.99578, 3.33, 0.62, 9.8, 'bad'], [6.7, 0.32, 0.44, 2.4, 0.061, 24, 34, 0.99484, 3.29, 0.8, 11.6, 'good'], [7.2, 0.39, 0.44, 2.6, 0.066, 22, 48, 0.99494, 3.3, 0.84, 11.5, 'good'], [7.5, 0.31, 0.41, 2.4, 0.065, 34, 60, 0.99492, 3.34, 0.85, 11.4, 'good'], [5.8, 0.61, 0.11, 1.8, 0.066, 18, 28, 0.99483, 3.55, 0.66, 10.9, 'good'], [7.2, 0.66, 0.33, 2.5, 0.068, 34, 102, 0.99414, 3.27, 0.78, 12.8, 'good'], [6.6, 0.725, 0.2, 7.8, 0.073, 29, 79, 0.9977, 3.29, 0.54, 9.2, 'bad'], [6.3, 0.55, 0.15, 1.8, 0.077, 26, 35, 0.99314, 3.32, 0.82, 11.6, 'good'], [5.4, 0.74, 0.09, 1.7, 0.089, 16, 26, 0.99402, 3.67, 0.56, 11.6, 'good'], [6.3, 0.51, 0.13, 2.3, 0.076, 29, 40, 0.99574, 3.42, 0.75, 11, 'good'], [6.8, 0.62, 0.08, 1.9, 0.068, 28, 38, 0.99651, 3.42, 0.82, 9.5, 'good'], [6.2, 0.6, 0.08, 2, 0.09, 32, 44, 0.9949, 3.45, 0.58, 10.5, 'bad'], [5.9, 0.55, 0.1, 2.2, 0.062, 39, 51, 0.99512, 3.52, 0.76, 11.2, 'good'], [6.3, 0.51, 0.13, 2.3, 0.076, 29, 40, 0.99574, 3.42, 0.75, 11, 'good'], [5.9, 0.645, 0.12, 2, 0.075, 32, 44, 0.99547, 3.57, 0.71, 10.2, 'bad'], [6, 0.31, 0.47, 3.6, 0.067, 18, 42, 0.99549, 3.39, 0.66, 11, 'good']]


if __name__ == '__main__':
    C = int(input())
    P = int(input())

    new_dataset = [
        [row[0] + row[10]] + row[1:10] + [row[-1]]
        for row in dataset
    ]

    classes = set([row[-1] for row in new_dataset])

    train_X, train_Y, test_X, test_Y = [], [], [], []
    for class_ in ['good', 'bad']:
        dataset_class = [row for row in new_dataset if row[-1] == class_]
        X, Y = [row[:-1] for row in dataset_class], [row[-1] for row in dataset_class]

        if C == 0:
            train_X_c, test_X_c, train_Y_c, test_Y_c = \
                X[:int(len(X) * P / 100)], \
                X[int(len(X) * P / 100):], \
                Y[:int(len(Y) * P / 100)], \
                Y[int(len(Y) * P / 100):]
        else:
            train_X_c, test_X_c, train_Y_c, test_Y_c = \
                X[int(len(X) * (100 - P) / 100):], \
                X[:int(len(X) * (100 - P) / 100)], \
                Y[int(len(Y) * (100 - P) / 100):], \
                Y[:int(len(Y) * (100 - P) / 100)]

        train_X.extend(train_X_c)
        test_X.extend(test_X_c)
        train_Y.extend(train_Y_c)
        test_Y.extend(test_Y_c)

    scaler = MinMaxScaler(feature_range=(-1, 1))
    train_X_2 = scaler.fit_transform(train_X)
    test_X_2 = scaler.transform(test_X)

    bayes_1 = GaussianNB()
    bayes_1.fit(train_X, train_Y)
    bayes_2 = GaussianNB()
    bayes_2.fit(train_X_2, train_Y)

    print(f'Tochnost so zbir na koloni: {bayes_1.score(test_X, test_Y)}')
    print(f'Tochnost so zbir na koloni i skaliranje: {bayes_2.score(test_X_2, test_Y)}')
